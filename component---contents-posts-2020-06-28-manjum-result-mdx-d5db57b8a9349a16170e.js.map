{"version":3,"file":"component---contents-posts-2020-06-28-manjum-result-mdx-d5db57b8a9349a16170e.js","mappings":"sJAGA,SAASA,EAAkBC,GACzB,MAAMC,EAAcC,OAAOC,OAAO,CAChCC,GAAI,KACJC,GAAI,KACJC,GAAI,KACJC,EAAG,IACHC,IAAK,MACLC,KAAM,OACNC,GAAI,KACJC,EAAG,IACHC,GAAI,KACJC,KAAM,SACLC,EAAAA,EAAAA,MAAsBd,EAAMe,YAC/B,OAAOC,EAAAA,cAAoBA,EAAAA,SAAgB,KAAMA,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,MAAO,MAAO,KAAMW,EAAAA,cAAoBf,EAAYK,GAAI,KAAM,MAAO,KAAMU,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,uPAAwP,KAAMS,EAAAA,cAAoBf,EAAYK,GAAI,KAAM,MAAO,KAAMU,EAAAA,cAAoBf,EAAYO,IAAK,KAAMQ,EAAAA,cAAoBf,EAAYQ,KAAM,KAAM,8DAA+D,KAAMO,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,UAAW,KAAMM,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,gBAAiB,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,UAAW,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,SAAU,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,WAAY,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAMW,EAAAA,cAAoBf,EAAYU,EAAG,CACxnCM,KAAM,wCACL,sBAAuB,MAAO,KAAMD,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,OAAQ,KAAMM,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,qLAAsL,KAAMS,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,4BAA6B,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,2BAA4B,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,mGAAoG,MAAO,KAAMW,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,UAAW,KAAMM,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,8FAA+F,KAAMS,EAAAA,cAAoBf,EAAYO,IAAK,KAAMQ,EAAAA,cAAoBf,EAAYQ,KAAM,CACh8BS,UAAW,mBACV,mlBAAolB,KAAMF,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,+FAAgG,KAAMS,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,WAAY,KAAMM,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,sIAAuI,KAAMS,EAAAA,cAAoBf,EAAYO,IAAK,KAAMQ,EAAAA,cAAoBf,EAAYQ,KAAM,CAC7iCS,UAAW,mBACV,o+CAAq+C,KAAMF,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,QAAS,KAAMM,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,gCAAiC,KAAMS,EAAAA,cAAoBf,EAAYW,GAAI,KAAM,KAAMI,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,mCAAoC,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,mCAAoC,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,gCAAiC,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,8FAA+F,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,8BAA+B,MAAO,KAAMW,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,0BAA2BS,EAAAA,cAAoBf,EAAYU,EAAG,CAC1uEM,KAAM,yBACL,MAAO,gBAAiB,KAAMD,EAAAA,cAAoBf,EAAYO,IAAK,KAAMQ,EAAAA,cAAoBf,EAAYQ,KAAM,CAChHS,UAAW,mBACV,yoBAA0oB,KAAMF,EAAAA,cAAoBf,EAAYK,GAAI,KAAM,MAAO,KAAMU,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,UAAW,KAAMM,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,iCAAkC,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,kCAAmC,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,qCAAsC,MAAO,KAAMW,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,8CAA+C,KAAMS,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,WAAY,KAAMM,EAAAA,cAAoBf,EAAYO,IAAK,KAAMQ,EAAAA,cAAoBf,EAAYQ,KAAM,CAChyCS,UAAW,mBACV,oXAA6X,KAAMF,EAAAA,cAAoBf,EAAYY,KAAM,CAC1aM,wBAAyB,CACvBC,OAAQ,mpDAER,KAAMJ,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,wDAAyD,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,iOAAkO,KAAMW,EAAAA,cAAoBf,EAAYI,GAAI,KAAM,wSAAyS,MAAO,KAAMW,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,SAAU,KAAMM,EAAAA,cAAoBf,EAAYG,GAAI,KAAM,KAAMY,EAAAA,cAAoBf,EAAYI,GAAI,KAAMW,EAAAA,cAAoBf,EAAYU,EAAG,CAC18BM,KAAM,8BACL,mEAAoE,KAAMD,EAAAA,cAAoBf,EAAYI,GAAI,KAAMW,EAAAA,cAAoBf,EAAYU,EAAG,CACxJM,KAAM,mCACL,eAAgB,MAAO,KAAMD,EAAAA,cAAoBf,EAAYS,GAAI,KAAM,MAAO,KAAMM,EAAAA,cAAoBf,EAAYM,EAAG,KAAM,4DAClI,CAKA,UAJA,SAAoBP,QAAK,IAALA,IAAAA,EAAQ,CAAC,GAC3B,MAAOqB,QAASC,GAAapB,OAAOC,OAAO,CAAC,GAAGW,EAAAA,EAAAA,MAAsBd,EAAMe,YAC3E,OAAOO,EAAYN,EAAAA,cAAoBM,EAAWtB,EAAOgB,EAAAA,cAAoBjB,EAAmBC,IAAUD,EAAkBC,EAC9H,C,8FCRO,MAAMuB,EAAa,gBAAoB,CAAC,GAiCxC,SAASC,EAAiBT,GAC/B,MAAMU,EAAoB,aAAiBF,GAG3C,OAAO,WAAc,IAEO,mBAAfR,EACFA,EAAWU,GAGb,IAAIA,KAAsBV,IAChC,CAACU,EAAmBV,GACzB,CAGA,MAAMW,EAAc,CAAC,EAQd,SAASC,GAAY,WAACZ,EAAU,SAAEa,EAAQ,qBAAEC,IAEjD,IAAIC,EAWJ,OAREA,EADED,EAEsB,mBAAfd,EACHA,EAAW,CAAC,GACZA,GAAcW,EAEJF,EAAiBT,GAG5B,gBACLQ,EAAWQ,SACX,CAACC,MAAOF,GACRF,EAEJ,C","sources":["webpack://new-gatsby-blog/./contents/posts/2020-06-28-manjum-result.mdx","webpack://new-gatsby-blog/./node_modules/@mdx-js/react/lib/index.js"],"sourcesContent":["/*@jsxRuntime classic @jsx React.createElement @jsxFrag React.Fragment*/\nimport {useMDXComponents as _provideComponents} from \"@mdx-js/react\";\nimport React from \"react\";\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    ul: \"ul\",\n    li: \"li\",\n    h2: \"h2\",\n    p: \"p\",\n    pre: \"pre\",\n    code: \"code\",\n    h3: \"h3\",\n    a: \"a\",\n    ol: \"ol\",\n    span: \"span\"\n  }, _provideComponents(), props.components);\n  return React.createElement(React.Fragment, null, React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"목차\"), \"\\n\"), \"\\n\", React.createElement(_components.h2, null, \"목표\"), \"\\n\", React.createElement(_components.p, null, \"작년 겨울, 만점프로젝트에서 뉴스 데이터를 활용한 가치평가 프로젝트를 진행했다. 기업에 대한 뉴스를 크롤링한 뒤 긍정/부정 기사들의 양을 비교하고 싶었다. 또한 kSDG(Korea Sustainable Development Goals) 기준으로 기사를 분류해서 특정 기업의 가치, 긍정/부정 행위 평가를 자동화하는 것이 목표다. 이번 글에서는 뉴스 본문 데이터를 크롤링하고 긍정/부정을 평가하는 머신러닝 모델을 만드는 방법을 소개한다.\"), \"\\n\", React.createElement(_components.h2, null, \"방법\"), \"\\n\", React.createElement(_components.pre, null, React.createElement(_components.code, null, \"이 글은 파이썬을 어느 정도 사용할 줄 알고 머신러닝에 대한 배경지식이 있는 독자를 대상으로 한다.\\n\")), \"\\n\", React.createElement(_components.h3, null, \"사용한 도구\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"Python 3.7.5\"), \"\\n\", React.createElement(_components.li, null, \"konlpy\"), \"\\n\", React.createElement(_components.li, null, \"keras\"), \"\\n\", React.createElement(_components.li, null, \"asyncio\"), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.a, {\n    href: \"https://github.com/MartianLee/manjum\"\n  }, \"크롤링, 머신러닝에 사용한 코드\")), \"\\n\"), \"\\n\", React.createElement(_components.h3, null, \"크롤링\"), \"\\n\", React.createElement(_components.p, null, \"python 3.7부터 기본적으로 제공하는 비동기 라이브러리 asyncio를 활용해 빠른 크롤링\\n뉴스 데이터 플랫폼 빅카인즈에서는 뉴스 데이터 검색결과를 제공하는데, 본문 검색을 지원하지 않아 직접 크롤링하였다. 크롤링 이후 파싱한 데이터들이 예측에 어긋나는 것들이 많아 database가 가끔 터져서 애를 먹었다.\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"키워드가 5000바이트가 넘는 row가 있음\"), \"\\n\", React.createElement(_components.li, null, \"기사 입력 시간이 null인 row가 있음\"), \"\\n\", React.createElement(_components.li, null, \"그 외 null이거나 값이 이상한 데이터 다수.\\n이후 파싱하는 로직이 완성되고 나서 asyncio를 도입해 비동기로 페이지를 요청해 파싱하니 크롤링 속도가 아주 빨랐다.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, null, \"형태소 분석\"), \"\\n\", React.createElement(_components.p, null, \"파이썬 한글 형태소분석 라이브러리인 konlpy를 사용했다. 신조어를 제외하면 아주 잘 작동한다. 명사 데이터베이스도 커스텀 가능하다. 태그는 Okt를 사용했다.\"), \"\\n\", React.createElement(_components.pre, null, React.createElement(_components.code, {\n    className: \"language-python\"\n  }, \"# 불용어\\nstopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', 'br', '/><', '/>', '.<']\\n\\nfrom konlpy.tag import Okt\\nfrom konlpy.utils import pprint\\n\\nokt = Okt()\\n\\nall_nouns = []\\nall_nouns2 = []\\nfor row in train_data:\\n    temp_X = okt.morphs(row[3], stem=True) # 토큰화\\n    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\\n    all_nouns.append(temp_X)\\n\\nfor row in test_data:\\n    temp_X = okt.morphs(row[3], stem=True) # 토큰화\\n    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거\\n    all_nouns2.append(temp_X)\\n\")), \"\\n\", React.createElement(_components.p, null, \"라이브러리 사용방법은 아주 쉽다. Okt를 인스턴스화한다음 okt.morphs(토큰화 할 string, stem여부)를 입력하면 string array를 반환한다.\"), \"\\n\", React.createElement(_components.h3, null, \"데이터 모델링\"), \"\\n\", React.createElement(_components.p, null, \"형태소 분석은 생각보다 어렵지 않았다. 다음으로 텍스트 행렬을 머신러닝 모델에 학습시킬 수 있게 numpy array 형태로 예쁘게 가공해야 한다. 또한 raw text가 아니고 text의 번호를 붙여줘서 벡터화하는 작업이 필요하다.\"), \"\\n\", React.createElement(_components.pre, null, React.createElement(_components.code, {\n    className: \"language-python\"\n  }, \"# 데이터 토큰화\\nfrom keras.preprocessing.text import Tokenizer\\nimport json\\n\\nmax_words = 10000\\ntokenizer = Tokenizer(num_words = max_words)\\ntokenizer.fit_on_texts(all_nouns)\\n\\nfrom datetime import datetime\\nnow = datetime.now()\\ncurrent_time = now.strftime(\\\"%H-%M-%S\\\")\\noutputfilename = 'all_nouns' + current_time + '.json'\\n\\nwith open(outputfilename, 'w') as outfile:\\n    json.dump(all_nouns, outfile)\\n\\nX_train = tokenizer.texts_to_sequences(all_nouns)\\nX_test = tokenizer.texts_to_sequences(all_nouns2)\\n\\nprint(\\\"본문의 최대 길이 : \\\", max(len(l) for l in X_train))\\nprint(\\\"본문의 평균 길이 : \\\", sum(map(len, X_train))/ len(X_train))\\n\\n# 결과를 차트로 출력\\nimport matplotlib.pyplot as plt\\nplt.hist([len(s) for s in X_train], bins=50)\\nplt.xlabel('length of Data')\\nplt.ylabel('number of Data')\\nplt.show()\\n\\n# 학습 데이터, 테스트 데이터 분리\\nimport numpy as np\\ny_train = []\\ny_test = []\\n\\ntype_of_result = 18\\ny_result = []\\nfor i in range(type_of_result):\\n    temp = []\\n    for j in range(type_of_result):\\n        if j == i:\\n            temp.append(1)\\n        else:\\n            temp.append(0)\\n    y_result.append(temp.copy())\\n\\nfor i in range(len(train_data)):\\n    for type in range(type_of_result):\\n        if train_data[i][4] == type:\\n            y_train.append(y_result[type].copy())\\n\\nfor i in range(len(test_data)):\\n    for type in range(type_of_result):\\n        if test_data[i][4] == type:\\n            y_test.append(y_result[type].copy())\\n\\ny_train = np.array(y_train)\\ny_test = np.array(y_test)\\n\")), \"\\n\", React.createElement(_components.h3, null, \"머신러닝\"), \"\\n\", React.createElement(_components.p, null, \"최종적인 정확도에 가장 큰 영향을 끼치는 과정이다.\"), \"\\n\", React.createElement(_components.ol, null, \"\\n\", React.createElement(_components.li, null, \"max_len으로 총 단어의 갯수 제한 (ex. 300)\"), \"\\n\", React.createElement(_components.li, null, \"Embedding을 몇차원으로 할 것인지 (ex. 60)\"), \"\\n\", React.createElement(_components.li, null, \"LSTM 레이어를 몇 개 둘 것인지 (ex. 30)\"), \"\\n\", React.createElement(_components.li, null, \"모델의 최적화를 어떤 optimizier를 사용할 것인지, 손실 모델은 무엇으로 할 것인지(ex. 'adam', 'categorical_crossentropy')\"), \"\\n\", React.createElement(_components.li, null, \"몇 번 반복해서 학습시킬 것인지 (ex. 10)\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"자세한 keras.models의 사용법은 \", React.createElement(_components.a, {\n    href: \"https://keras.io/api/\"\n  }, \"이곳\"), \"에서 확인할 수 있다.\"), \"\\n\", React.createElement(_components.pre, null, React.createElement(_components.code, {\n    className: \"language-python\"\n  }, \"from keras.layers import Embedding, Dense, LSTM\\nfrom keras.models import Sequential\\nfrom keras.preprocessing.sequence import pad_sequences\\nmax_len = 300 # 전체 데이터의 길이를 300으로 맞춘다\\nX_train = pad_sequences(X_train, maxlen=max_len)\\nX_test = pad_sequences(X_test, maxlen=max_len)\\n\\nmodel = Sequential()\\nmodel.add(Embedding(max_words, 60))\\nmodel.add(LSTM(30))\\nmodel.add(Dense(type_of_result, activation='softmax'))\\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=10, validation_split=0.1)\\nmodel.save('lstm_model_yn_'+ current_time + '.h5')\\n\")), \"\\n\", React.createElement(_components.h2, null, \"결과\"), \"\\n\", React.createElement(_components.h3, null, \"크롤링 속도\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"180회, 2700ms; 1 request: 15ms\"), \"\\n\", React.createElement(_components.li, null, \"9380회, 84000ms; 1 request: 9ms\"), \"\\n\", React.createElement(_components.li, null, \"17036회, 201449ms; 1 request: 12ms\"), \"\\n\"), \"\\n\", React.createElement(_components.p, null, \"크롤링은 python + asyncio + beautifulsoup 입니다.\"), \"\\n\", React.createElement(_components.h3, null, \"긍/부정 분석\"), \"\\n\", React.createElement(_components.pre, null, React.createElement(_components.code, {\n    className: \"language-python\"\n  }, \"res = model.evaluate(X_test, y_test)\\nprint(f\\\"테스트 정확도 : {res[1] * 100}%\\\")\\n\\n# 예측한 값 비교하기\\npredict = model.predict(X_test)\\nimport numpy as np\\npredict_labels = np.argmax(predict, axis=1)\\noriginal_labels = np.argmax(y_test, axis=1)\\nfor i in range(50):\\n    print(\\\"기사제목 : \\\", test_data[i][2], \\\"/\\\\t 원래 라벨 : \\\", original_labels[i], \\\"/\\\\t예측한 라벨 : \\\", predict_labels[i])\\n\")), \"\\n\", React.createElement(_components.span, {\n    dangerouslySetInnerHTML: {\n      __html: \"<span\\n      class=\\\"gatsby-resp-image-wrapper\\\"\\n      style=\\\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \\\"\\n    >\\n      <a\\n    class=\\\"gatsby-resp-image-link\\\"\\n    href=\\\"/static/4dcb983e14533877ce0f89e351a1ba3f/df88b/pn.png\\\"\\n    style=\\\"display: block\\\"\\n    target=\\\"_blank\\\"\\n    rel=\\\"noopener\\\"\\n  >\\n    <span\\n    class=\\\"gatsby-resp-image-background-image\\\"\\n    style=\\\"padding-bottom: 21.999999999999996%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAlklEQVR42lWPWw6FIAxE2Y+CGAUFfHAN+99Sb04TjX5MZqDtKZjWmpznKcuySIxRRQ4hSClF5nnWjMh3zzRNH79lav3Jvu+ybZsAv65LgQynlNS99+Kck2EYZBxHzYhMjXvO1loxx3EoGShAzoB4HRnPOeuS9y/WdX0WAuq6TmX4LkX8rVqrLmEIB0ofUDIC1vf9AwP4B8eggyEE7ETeAAAAAElFTkSuQmCC'); background-size: cover; display: block;\\\"\\n  ></span>\\n  <img\\n        class=\\\"gatsby-resp-image-image\\\"\\n        alt=\\\"img\\\"\\n        title=\\\"\\\"\\n        src=\\\"/static/4dcb983e14533877ce0f89e351a1ba3f/5a190/pn.png\\\"\\n        srcset=\\\"/static/4dcb983e14533877ce0f89e351a1ba3f/772e8/pn.png 200w,\\n/static/4dcb983e14533877ce0f89e351a1ba3f/e17e5/pn.png 400w,\\n/static/4dcb983e14533877ce0f89e351a1ba3f/5a190/pn.png 800w,\\n/static/4dcb983e14533877ce0f89e351a1ba3f/c1b63/pn.png 1200w,\\n/static/4dcb983e14533877ce0f89e351a1ba3f/29007/pn.png 1600w,\\n/static/4dcb983e14533877ce0f89e351a1ba3f/df88b/pn.png 1906w\\\"\\n        sizes=\\\"(max-width: 800px) 100vw, 800px\\\"\\n        style=\\\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\\\"\\n        loading=\\\"lazy\\\"\\n        decoding=\\\"async\\\"\\n      />\\n  </a>\\n    </span>\"\n    }\n  }), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, \"한 기사당 max_len에 따라서 정확도가 달라진다. 길수록 정확하지만 생성 속도는 느려진다.\"), \"\\n\", React.createElement(_components.li, null, \"Embedding 차원과 LSTM Layer의 갯수는 모델의 크기에 큰 영향을 끼친다. 나는 GCP 혹은 Heroku에서 작동할 수 있는 크기 (메모리 300mb)로 만들기 위해 커스터마이징하였다. 차원과 레이어를 늘리면 정확도가 개선된다. 하지만 제한된 inpu에서 차원과 레이어만 늘린다고 해서 정확도가 개선되지는 않는다. (오히려 overfitting되어서 더 이상한 결과를 낼 수 있음.)\"), \"\\n\", React.createElement(_components.li, null, \"몇 번 반복해서 학습시킬지(epochs)는 10번 내외가 결과가 좋았다. 너무 적게 반복하거나 너무 많이 반복하면 정확도가 좋지 않았다.\\n긍,부정 분석 결과는 아주 좋았다(평가 데이터 기준 96%). LSTM이 긍,부정 평가에 좋다는 글을 보고 적용해 보았는데 이렇게 좋을 줄은 몰랐다. 이정도 정확도면 가치 평가 이전에 어떤 기사가 긍정적인 기사인지 부정적인 기사인지 평가하는 일은 충분히 자동화할 수 있을 것 같다. 텍스트 본문 기반으로 긍,부정 평가 문제를 해결해야 하는 사람은 LSTM 모델 적용을 적극 추천한다.\"), \"\\n\"), \"\\n\", React.createElement(_components.h3, null, \"참고한 글\"), \"\\n\", React.createElement(_components.ul, null, \"\\n\", React.createElement(_components.li, null, React.createElement(_components.a, {\n    href: \"https://wikidocs.net/22933\"\n  }, \"딥 러닝을 이용한 자연어 처리 입문 - 로이터 뉴스 분류하기(Reuters News Classification)\")), \"\\n\", React.createElement(_components.li, null, React.createElement(_components.a, {\n    href: \"https://lsjsj92.tistory.com/409\"\n  }, \"케라스로 딥러닝하자\")), \"\\n\"), \"\\n\", React.createElement(_components.h3, null, \"다음\"), \"\\n\", React.createElement(_components.p, null, \"다음은 위에서 학습시킨 머신러닝 모델을 클라우드(GAE + Heroku)에 배포하는 방법을 알아본다.\"));\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? React.createElement(MDXLayout, props, React.createElement(_createMdxContent, props)) : _createMdxContent(props);\n}\nexport default MDXContent;\n","/**\n * @typedef {import('react').ReactNode} ReactNode\n * @typedef {import('mdx/types.js').MDXComponents} Components\n *\n * @typedef Props\n *   Configuration.\n * @property {Components | MergeComponents | null | undefined} [components]\n *   Mapping of names for JSX components to React components.\n * @property {boolean | null | undefined} [disableParentContext=false]\n *   Turn off outer component context.\n * @property {ReactNode | null | undefined} [children]\n *   Children.\n *\n * @callback MergeComponents\n *   Custom merge function.\n * @param {Components} currentComponents\n *   Current components from the context.\n * @returns {Components}\n *   Merged components.\n */\n\nimport React from 'react'\n\n/**\n * @type {import('react').Context<Components>}\n * @deprecated\n *   This export is marked as a legacy feature.\n *   That means it’s no longer recommended for use as it might be removed\n *   in a future major release.\n *\n *   Please use `useMDXComponents` to get context based components and\n *   `MDXProvider` to set context based components instead.\n */\nexport const MDXContext = React.createContext({})\n\n/**\n * @param {import('react').ComponentType<any>} Component\n * @deprecated\n *   This export is marked as a legacy feature.\n *   That means it’s no longer recommended for use as it might be removed\n *   in a future major release.\n *\n *   Please use `useMDXComponents` to get context based components instead.\n */\nexport function withMDXComponents(Component) {\n  return boundMDXComponent\n\n  /**\n   * @param {Record<string, unknown> & {components?: Components | null | undefined}} props\n   * @returns {JSX.Element}\n   */\n  function boundMDXComponent(props) {\n    const allComponents = useMDXComponents(props.components)\n    return React.createElement(Component, {...props, allComponents})\n  }\n}\n\n/**\n * Get current components from the MDX Context.\n *\n * @param {Components | MergeComponents | null | undefined} [components]\n *   Additional components to use or a function that takes the current\n *   components and filters/merges/changes them.\n * @returns {Components}\n *   Current components.\n */\nexport function useMDXComponents(components) {\n  const contextComponents = React.useContext(MDXContext)\n\n  // Memoize to avoid unnecessary top-level context changes\n  return React.useMemo(() => {\n    // Custom merge via a function prop\n    if (typeof components === 'function') {\n      return components(contextComponents)\n    }\n\n    return {...contextComponents, ...components}\n  }, [contextComponents, components])\n}\n\n/** @type {Components} */\nconst emptyObject = {}\n\n/**\n * Provider for MDX context\n *\n * @param {Props} props\n * @returns {JSX.Element}\n */\nexport function MDXProvider({components, children, disableParentContext}) {\n  /** @type {Components} */\n  let allComponents\n\n  if (disableParentContext) {\n    allComponents =\n      typeof components === 'function'\n        ? components({})\n        : components || emptyObject\n  } else {\n    allComponents = useMDXComponents(components)\n  }\n\n  return React.createElement(\n    MDXContext.Provider,\n    {value: allComponents},\n    children\n  )\n}\n"],"names":["_createMdxContent","props","_components","Object","assign","ul","li","h2","p","pre","code","h3","a","ol","span","_provideComponents","components","React","href","className","dangerouslySetInnerHTML","__html","wrapper","MDXLayout","MDXContext","useMDXComponents","contextComponents","emptyObject","MDXProvider","children","disableParentContext","allComponents","Provider","value"],"sourceRoot":""}